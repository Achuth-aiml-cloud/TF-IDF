# -*- coding: utf-8 -*-
"""TF*IDF.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1qfWSqXAfFoKIWvVSWb3Q7jywCOgL0-xA

***TF-IDF*** : Term Frequency and inverse document frequency

tf = (total no of repeated words / to no of words in that sentence )

---


idf = log( total no of sentences / total no of sentences that containing the particular word)
"""

import nltk

paragraph = """At SpaceX, Musk oversees the development of rockets and spacecraft for missions to Earth orbit and ultimately to other planets. In 2008, SpaceXâ€™s Falcon 9 rocket and Dragon spacecraft won the NASA contract to provide cargo transport to space. In 2012, SpaceX became the first commercial company to dock with the International Space Station and return cargo to Earth with the Dragon.

At Tesla, Musk has overseen product development and design from the beginning, including the all-electric Tesla Roadster, Model S and Model X, and the rollout of Supercharger stations to keep the cars juiced up. (Some of the charging stations use solar energy systems from SolarCity, of which Musk is the non-executive chair.) Transitioning to a sustainable energy economy, in which electric vehicles play a pivotal role, has been one of his central interests for almost two decades. Before this, he co-founded PayPal and served as the company's chair and CEO."""

import re
from nltk.corpus import stopwords
from nltk.stem import PorterStemmer
from nltk.stem import WordNetLemmatizer

nltk.download('punkt')

sentences = nltk.sent_tokenize(paragraph)

sentences

nltk.download('stopwords')

nltk.download('wordnet')

wnl = WordNetLemmatizer()
empty_list = []
for i in range(len(sentences)):
  clean_us_lem = re.sub('[^a-zA-Z]',' ',sentences[i])
  clean_us_lem = clean_us_lem.lower()
  clean_us_lem = clean_us_lem.split()
  clean_us_lem = [wnl.lemmatize(word) for word in clean_us_lem if word not in set(stopwords.words('english'))]
  clean_us_lem = " ".join(clean_us_lem)
  empty_list.append(clean_us_lem)

empty_list

#tfidf model
from sklearn.feature_extraction.text import TfidfVectorizer
final_matrix = TfidfVectorizer().fit_transform(empty_list).toarray()

final_matrix